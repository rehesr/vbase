{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f47037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import os\n",
    "from datetime import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from new_regression_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b2c058",
   "metadata": {},
   "outputs": [],
   "source": [
    "constituents = pd.read_csv('constituents.csv')\n",
    "weights_df = pd.read_excel('holdings-daily-us-en-spy.xlsx', skiprows=4, skipfooter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85953923",
   "metadata": {},
   "outputs": [],
   "source": [
    "st = pd.read_csv('sentiment_all_symbols.csv')\n",
    "st.rename(columns={'created_at':'time'},inplace=True)\n",
    "cons = constituents['Symbol']\n",
    "st = st[st['symbol'].isin(cons)]\n",
    "st['normalized_sentiment'] = st.groupby('time')['sentiment'].transform(lambda x: (x - x.mean()) / x.std() if x.std() != 0 else 0)\n",
    "st['normalized_volume'] = st.groupby('time')['message_volume'].transform(lambda x: (x - x.mean()) / x.std() if x.std() != 0 else 0)\n",
    "st['sentiment_change'] = st.groupby('symbol')['sentiment'].transform(\n",
    "    lambda x: np.where(x != 0, x.shift(-1)/x - 1, 0)\n",
    ")\n",
    "st['normalized_sentiment_change'] = st.groupby('time')['sentiment_change'].transform(lambda x: (x - x.mean()) / x.std() if x.std() != 0 else 0)\n",
    "st['volume_change'] = st.groupby('symbol')['message_volume'].transform(\n",
    "    lambda x: np.where(x != 0, x.shift(-1)/x - 1, 0)\n",
    ")\n",
    "st['normalized_volume_change'] = st.groupby('time')['volume_change'].transform(lambda x: (x - x.mean()) / x.std() if x.std() != 0 else 0)\n",
    "st.fillna(0,inplace=True)\n",
    "st.index = pd.to_datetime(st.index,unit='ns', utc=True)\n",
    "st_factors = st[['symbol','normalized_sentiment','normalized_volume','normalized_sentiment_change','normalized_volume_change']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d39e1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract data for 2023\n",
    "base_dir = \"validityBase/stock_data/2023/\"\n",
    "months = ['0'+str(i)+'/'  if i < 10 else str(i)+'/' for i in range(1,13)]\n",
    "\n",
    "# Initialize empty DataFrames\n",
    "all_stocks = pd.DataFrame()\n",
    "symbols = constituents['Symbol']\n",
    "\n",
    "# Loop through directories and concatenate\n",
    "for month in months:\n",
    "    directory = base_dir + month\n",
    "    csv_files = [file for file in os.listdir(directory) if file.endswith('.csv')]\n",
    "    csv_files.sort()\n",
    "    for file in csv_files:\n",
    "        file_path = os.path.join(directory, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "        df = df[df['ticker'].isin(symbols)]\n",
    "        df['time'] = pd.to_datetime(df['window_start'],unit='ns', utc=True)\n",
    "        df.set_index('time',inplace=True)\n",
    "        df = df[df['ticker'].isin(symbols)]\n",
    "        df = df[df.index.time==time(16, 0)]\n",
    "        all_stocks = pd.concat([all_stocks, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28a67be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract data for 2024\n",
    "base_dir = \"validityBase/stock_data/2024/\"\n",
    "months = ['0'+str(i)+'/'  if i < 10 else str(i)+'/' for i in range(1,13)]\n",
    "\n",
    "# Loop through directories and concatenate\n",
    "for month in months:\n",
    "    directory = base_dir + month\n",
    "    csv_files = [file for file in os.listdir(directory) if file.endswith('.csv')]\n",
    "    csv_files.sort()\n",
    "    for file in csv_files:\n",
    "        file_path = os.path.join(directory, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "        df = df[df['ticker'].isin(symbols)]\n",
    "        df['time'] = pd.to_datetime(df['window_start'],unit='ns', utc=True)\n",
    "        df.set_index('time',inplace=True)\n",
    "        df = df[df['ticker'].isin(symbols)]\n",
    "        df = df[df.index.time==time(16, 0)]\n",
    "        all_stocks = pd.concat([all_stocks, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b48498",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stocks.sort_index(inplace=True)\n",
    "all_stocks['close'] = all_stocks.groupby('ticker')['close'].transform(lambda x: x.ffill())\n",
    "all_stocks['close'].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfea68be",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stocks['time'] = all_stocks.index\n",
    "all_stocks['returns'] = list(all_stocks.groupby('ticker').apply(lambda x:x['close'].shift(-1) / x['close'] - 1).reset_index()['close'])\n",
    "returns = all_stocks[['ticker','returns','time']]\n",
    "returns.rename(columns={'ticker':'symbol'},inplace=True)\n",
    "returns.index.name = 'date'\n",
    "returns['time'] = returns['time'].dt.floor('D')\n",
    "returns.dropna(inplace=True)\n",
    "all_returns = returns.copy()\n",
    "\n",
    "all_returns = all_returns.pivot_table(values='returns',index='time',columns='symbol')\n",
    "all_returns.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d95ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = all_returns.columns\n",
    "all_betas = {}\n",
    "all_residuals = {}\n",
    "for i in range(0,len(all_returns)-252,21):\n",
    "    betas = []\n",
    "    residuals = []\n",
    "    real_symbols = []\n",
    "    returns_cur = all_returns[i:i+252]\n",
    "    for s in symbols:\n",
    "        returns = returns_cur[s]\n",
    "        df_fact_rets =  st_factors[st_factors['symbol'] == s][['normalized_sentiment','normalized_volume','normalized_sentiment_change','normalized_volume_change']]\n",
    "        df_fact_rets = df_fact_rets[(df_fact_rets.index<=returns.index[-1])&(df_fact_rets.index>=returns.index[0])]\n",
    "\n",
    "        if len(returns) > 0 and len(df_fact_rets) > 0:\n",
    "            betas_final, residuals_final = robust_matrix_regression(\n",
    "                returns,\n",
    "                df_fact_rets,\n",
    "                0.5,\n",
    "                90, # half-life\n",
    "                10\n",
    "            )\n",
    "            betas.append(pd.Series(betas_final))\n",
    "            residuals.append(pd.Series(residuals_final))\n",
    "            real_symbols.append(s)\n",
    "    betas = pd.concat(betas,axis=1)\n",
    "    betas.columns = real_symbols\n",
    "    residuals = pd.concat(residuals,axis=1)\n",
    "    residuals.columns = real_symbols\n",
    "    all_betas[returns.index[0]] = betas\n",
    "    all_residuals[returns.index[0]] = residuals"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
